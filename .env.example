# ===========================================
# Santa AI Card Generator - Environment Config
# ===========================================

# ===================
# Gemini API (via LiteLLM proxy)
# ===================
GEMINI_API_KEY=your_litellm_api_key_here
# LiteLLM proxy API key
GEMINI_BASE_URL=https://litellm.pro-4.ru/v1
# LiteLLM proxy base URL
GEMINI_TEXT_MODEL=gemini-2.5-flash
# Model for text generation (no prefix needed)
GEMINI_IMAGE_MODEL=gemini/gemini-2.5-flash-image-preview
# Model for image generation (IMPORTANT: must have 'gemini/' prefix!)

# ===================
# Telegram Bot
# ===================
TELEGRAM_BOT_TOKEN=your_bot_token_here
# Get from: @BotFather in Telegram
TELEGRAM_CHAT_ID=-1001234567890
# Chat ID where cards will be sent (use @getmyid_bot to find it)
TELEGRAM_TOPIC_ID=123
# Topic/thread ID in the chat (optional, use 0 for main chat)

# ===================
# Application Settings
# ===================
DEBUG=false
# Enable debug mode (true/false)

LOG_LEVEL=INFO
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL

MAX_REGENERATIONS=3
# Maximum number of regenerations allowed per card element

# ===================
# Data Storage
# ===================
EMPLOYEES_FILE_PATH=/app/data/employees.json
# Path to the employees JSON file (inside Docker container)

# ===================
# CORS Settings (Backend)
# ===================
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
# Allowed origins for CORS (comma-separated)

# ===================
# Frontend Environment Variables
# ===================
# Note: These are used during frontend build
VITE_API_URL=http://localhost:8000
# Backend API URL for frontend

# ===================
# Optional: Production Settings
# ===================
# BACKEND_HOST=0.0.0.0
# BACKEND_PORT=8000
# FRONTEND_PORT=80
